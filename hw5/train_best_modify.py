# -*- coding: utf-8 -*-
"""ml-2021-fall-hw5.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1iGWE9Lx46gM3-Xm3837KYzw1EojwM9Mc

# Import Module
"""

import csv
import time
import sys
import os
import random

# other library
import numpy as np
import pandas as pd
from PIL import Image
from sklearn.cluster import KMeans
from sklearn.decomposition import PCA
from sklearn.manifold import TSNE

# PyTorch library
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torch.utils import data

import matplotlib.pyplot as plt

"""# Set Hyper-parameters"""

NUM_EPOCH = 300
BATCH_SIZE = 256
LATENT_DIM = 0
REDUCED_DIM = 2
MODEL_NAME = 'model_best_test.pth'
lr = 5e-3

DATA_PATH = 'trainX.npy'
DEVICE_ID = 0
SEED = 1040

torch.cuda.set_device(DEVICE_ID)
use_gpu = torch.cuda.is_available()
device = torch.device("cuda" if use_gpu else "cpu")

torch.backends.cudnn.deterministic = True
torch.backends.cudnn.benchmark = False
torch.manual_seed(SEED)
torch.cuda.manual_seed_all(SEED)
random.seed(SEED)
np.random.seed(SEED)

"""# Define Dataset"""

class Dataset(data.Dataset):
    def __init__(self, data_path):
        self.total_img = torch.from_numpy(np.load(data_path)).float()
        self.total_img = self.total_img.permute(0, 3, 1, 2)
        
    def normalize(self, img):
        # TODO
        img = img / 255
        return img
    
    def augment(self, img):
        # TODO
        return img
    
    def __len__(self):
        return len(self.total_img)

    def __getitem__(self, index):
        img = self.total_img[index]
        img_aug = self.augment(img)
        
        img_aug = self.normalize(img_aug)
        img = self.normalize(img)
        return img_aug, img

"""# Define Model Architerchure"""

class Flatten(nn.Module):
    def forward(self, input):
        return input.view(input.size(0), -1)

class UnFlatten(nn.Module):
    def forward(self, input, size=256):
        return input.view(input.size(0), size, 1, 1)
    
class Net(nn.Module):
    def __init__(self, image_channels=3, latent_dim=64):
        super(Net, self).__init__()
        self.latent_dim = latent_dim
        
        self.encoder = nn.Sequential(
            nn.Conv2d(3, 32, kernel_size=(4, 4), stride=(2, 2), padding=1),
            nn.BatchNorm2d(32),
            nn.LeakyReLU(0.01, inplace=True),
            
            nn.Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2), padding=1),
            nn.BatchNorm2d(64),
            nn.LeakyReLU(0.01, inplace=True),
            
            nn.Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=1),
            nn.BatchNorm2d(128),
            nn.LeakyReLU(0.01, inplace=True),
            
            nn.Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=1),
            nn.BatchNorm2d(256),
            nn.LeakyReLU(0.01, inplace=True),
        )
        
        # you should check the latent dimension (N)
        #self.fc1 = nn.Linear(128*256*2*2, self.latent_dim)
        #self.fc2 = nn.Linear(self.latent_dim, 128*256*2*2)

        self.decoder = nn.Sequential(
            nn.ConvTranspose2d(256, 128, 4, 2, padding=1,bias=False),
            nn.BatchNorm2d(128),
            nn.LeakyReLU(0.01, inplace=True),
 
            nn.ConvTranspose2d(128, 64, 4, 2, padding=1,bias=False),
            nn.BatchNorm2d(64),
            nn.LeakyReLU(0.01, inplace=True),
 
            nn.ConvTranspose2d(64, 32, 4, 2, padding=1,bias=False),
            nn.BatchNorm2d(32),
            nn.LeakyReLU(0.01, inplace=True),
            
            nn.ConvTranspose2d(32, 3, 4, 2, padding=1,bias=False),
            nn.Tanh(),
        )
    
    def forward(self, x):
        """
        x = self.encoder(x)
        print ("x.shape:",x.shape)
        encoded = self.fc1(x)
        x_rec = self.decoder(self.fc2(encoded))
        return encoded, x_rec
        """
        x_encode = self.encoder(x)
        x_decode  = self.decoder(x_encode)
        #print ("Shape:",x.shape,"After encode shape:",x_encode.shape,", after decode shape:",x_decode.shape)
        return x_encode,x_decode

"""# Define Training Process"""

def training(train, val, model, device, n_epoch, batch, save_name):
    total = sum(p.numel() for p in model.parameters())
    trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)
    print('=== start training, parameter total:%d, trainable:%d' % (total, trainable))
    criterion = nn.MSELoss()
    optimizer = torch.optim.Adam(model.parameters(), lr=0.0001, weight_decay=1e-5)
    no_improve_time = 0
    best_loss = 100
    for epoch in range(n_epoch):
    # training set
        train_loss = 0
        model.train()
        for idx, (image_aug, image) in enumerate(train):
            image = image.to(device, dtype=torch.float)
            image_aug = image_aug.to(device, dtype=torch.float)
            _, reconstruct_train = model(image_aug)
            print ("reconstruct:",reconstruct_train.shape, end='\r')
            print ("image:",image.shape, end='\r')
            loss = criterion(reconstruct_train, image)

            optimizer.zero_grad()
            loss.backward()
            optimizer.step()
            train_loss += (loss.item() / len(train))

            print('[Epoch %d/%d | %d/%d] loss: %.4f' %
                 ((epoch+1), n_epoch, idx*batch, len(train)*batch, loss.item()), end='\r')
        print("\n  Training  | Loss:%.4f " % train_loss)

    # validation set
        model.eval()
        val_loss = 0
        with torch.no_grad():
            for idx, (image_aug, image) in enumerate(val):
                    image = image.to(device, dtype=torch.float)
                    image_aug = image_aug.to(device, dtype=torch.float)
                    image_aug = image_aug.to(device, dtype=torch.float)
                    _, reconstruct_test = model(image_aug)

                    loss = criterion(reconstruct_test, image)
                    val_loss += (loss.item() / len(val))
            
            print(" Validation | Loss:%.4f " % val_loss)
        # save model
        if val_loss < best_loss:
            best_loss = val_loss
            no_improve_time = 0
            print("saving model with loss %.4f...\n" % val_loss)
            torch.save(model.state_dict(), "%s" % save_name)
        else :
            no_improve_time += 1
            if (no_improve_time>5):
                break
        
        print("No improvement time:",no_improve_time)

# build dataset
dataset = Dataset(DATA_PATH)

# Random split
train_set_size = int(len(dataset) * 0.85)
valid_set_size = len(dataset) - train_set_size
train_set, valid_set = data.random_split(dataset, [train_set_size, valid_set_size])

# set data loader
train_loader = data.DataLoader(train_set, batch_size=128, num_workers=4, shuffle=True)
valid_loader = data.DataLoader(valid_set, batch_size=128, num_workers=4, shuffle=False)

if __name__ == '__main__':
    model = Net().to(device)
    training(train_loader, valid_loader, model, device, NUM_EPOCH, BATCH_SIZE, MODEL_NAME)